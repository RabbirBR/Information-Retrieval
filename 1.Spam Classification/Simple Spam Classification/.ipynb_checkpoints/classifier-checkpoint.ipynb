{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAT640 - Assignment 1a\n",
    "# Name:    Rabbir Bin Rabbani\n",
    "# ID:      247988\n",
    "# Team:    004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if the words library isn't already downloaded in this PC\n",
    "# import nltk\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import email\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# define wordlist and stopwords in English.\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "wordlists = set(nltk.corpus.words.words())\n",
    "\n",
    "\n",
    "from IPython.display import clear_output # Using IPython.display.clear_output to clear the output of a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_file_path = 'data/' # Change this to main data directory (keep the ending '/')\n",
    "\n",
    "data = pd.read_csv(main_file_path+'train/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_email_data(file_path):\n",
    "    print(file_path)\n",
    "    email_body, email_subject = \"\", \"\"\n",
    "    \n",
    "    mail = email.message_from_string(open(file_path, encoding = 'ISO-8859-1').read())\n",
    "    \n",
    "    # Get E-mail subject\n",
    "    email_subject = mail['subject']\n",
    "    \n",
    "    # Get E-mail body\n",
    "    if mail.is_multipart():\n",
    "        for payload in mail.get_payload():\n",
    "            # if payload.is_multipart() then.. \n",
    "            email_body = payload.get_payload()\n",
    "    else:\n",
    "        email_body = mail.get_payload()\n",
    "    \n",
    "    # If body has no value\n",
    "    if type(email_body) is not str:\n",
    "        # If body has no value then make it an empty string\n",
    "        if not email_body:\n",
    "            email_body = \"\"\n",
    "        # If body was multipart then the payload will be \n",
    "        # returned as an array with the first index as \n",
    "        # the actual message in the mail\n",
    "        elif type(email_body) is list:\n",
    "            email_body = email_body[0].as_string()\n",
    "    \n",
    "    if type(email_subject) is not str:\n",
    "        if not email_subject:\n",
    "            email_subject = \"\"\n",
    "        elif type(email_subject) is list:            \n",
    "            email_subject = email_subject[0]\n",
    "    \n",
    "    # Remove numbers and all special characters except space\n",
    "    email_body = re.sub(r'[^a-zA-Z]', ' ', email_body).lower()\n",
    "    email_subject = re.sub(r'[^a-zA-Z]', ' ', email_subject).lower()\n",
    "    \n",
    "    full_email = email_subject + email_body\n",
    "    \n",
    "    # Remove stopwords\n",
    "    full_email = ' '.join([word for word in full_email.split() if word not in (stopwords)])\n",
    "    \n",
    "    # remove words that are not part of the english dictionary - using nltk tokenizer (Wordlist can be found in cell 3)\n",
    "    full_email = \" \".join(w for w in nltk.wordpunct_tokenize(full_email) if w.lower() in wordlists or not w.isalpha())\n",
    "    \n",
    "    # Remove single letter words like 'b', 'j', etc..\n",
    "    full_email = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", full_email)\n",
    "    \n",
    "    clear_output()\n",
    "    return full_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/000/000</td>\n",
       "      <td>ham</td>\n",
       "      <td>june daily labor id original message sent june...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/000/002</td>\n",
       "      <td>ham</td>\n",
       "      <td>new original message sent june mark subject s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/000/003</td>\n",
       "      <td>ham</td>\n",
       "      <td>upstream company currently trading spot el ups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/000/004</td>\n",
       "      <td>ham</td>\n",
       "      <td>new master attached new master physical berry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/000/005</td>\n",
       "      <td>ham</td>\n",
       "      <td>upstream company copy communication regarding ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id Label                                              email\n",
       "0  train/000/000   ham  june daily labor id original message sent june...\n",
       "1  train/000/002   ham   new original message sent june mark subject s...\n",
       "2  train/000/003   ham  upstream company currently trading spot el ups...\n",
       "3  train/000/004   ham  new master attached new master physical berry ...\n",
       "4  train/000/005   ham  upstream company copy communication regarding ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['email'] = data.apply(lambda row: process_email_data(main_file_path+row['Id']), axis=1).apply(pd.Series)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82906 entries, 0 to 82905\n",
      "Data columns (total 3 columns):\n",
      "Id       82906 non-null object\n",
      "Label    82906 non-null object\n",
      "email    82906 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(data[['email']], data[['Label']], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption -\n",
    "#     Spam emails contains certain words more than Non-spam emails and vice-versa.\n",
    "\n",
    "# Idea for the Classifier -\n",
    "#     For training - Find the most common words in spam and non-spam emails.\n",
    "#     For prediction -\n",
    "#         1. Count how many spam and non-spam words are in the E-mail.\n",
    "#         2. If the mail has more spam words than non-spam words, then label the mail as spam, otherwise label it as ham.\n",
    "\n",
    "class EmailClassifier:\n",
    "    __frequent_spam_words = None\n",
    "    __frequent_ham_words = None\n",
    "    __word_percentage = 5 # What percent of most frequent words to take for checking during training (Default - 5%).\n",
    "    __model_is_trained = False\n",
    "    \n",
    "    def __init__(self, frequent_word_percentage = 5):\n",
    "        self.__word_percentage = frequent_word_percentage\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        self.__frequent_spam_words = None\n",
    "        self.__frequent_ham_words = None\n",
    "        self.__model_is_trained = False\n",
    "        \n",
    "        # Get the indexes of all labeled spam and ham mails\n",
    "        spam_indx = list(y_train[y_train['Label'] == 'spam'].index.values)\n",
    "        ham_indx = list(y_train[y_train['Label'] == 'ham'].index.values)\n",
    "\n",
    "        # Get all words in spam and ham emails\n",
    "        spam_words = X_train['email'][spam_indx].str.cat().split()\n",
    "        ham_words = X_train['email'][ham_indx].str.cat().split()\n",
    "        \n",
    "        uniq_word_count = len(set(X_train['email'].str.cat().split()))\n",
    "\n",
    "        # Take (__word_percentage)% of the most frequent spam and ham words\n",
    "        self.__frequent_spam_words = Counter(spam_words).most_common(round(uniq_word_count*(self.__word_percentage/100)))\n",
    "        self.__frequent_spam_words = [w[0] for w in self.__frequent_spam_words]\n",
    "        \n",
    "        self.__frequent_ham_words = Counter(ham_words).most_common(round(uniq_word_count*(self.__word_percentage/100)))\n",
    "        self.__frequent_ham_words = [w[0] for w in self.__frequent_ham_words]\n",
    "        \n",
    "        # Indicate that the model has been trained\n",
    "        self.__model_is_trained = True\n",
    "\n",
    "    def predict(self, X_vals):\n",
    "        predictions = []\n",
    "        \n",
    "        if self.__model_is_trained:\n",
    "            \n",
    "            total_size = X_vals.shape[0]\n",
    "            s = 0\n",
    "            for mail in X_vals['email']:\n",
    "                spam_words_count = 0\n",
    "                ham_words_count = 0\n",
    "                \n",
    "                unique_words_in_email = set(mail.split())\n",
    "                \n",
    "                # Calculate number of spam and ham matches with test set words\n",
    "                for word in unique_words_in_email:\n",
    "                    spam_words_count += 1 if word in self.__frequent_spam_words else 0\n",
    "                    ham_words_count += 1 if word in self.__frequent_ham_words else 0\n",
    "                \n",
    "                # If there are more spam matches than ham, then predict as spam, otherwise predict as ham\n",
    "                if(spam_words_count > ham_words_count):\n",
    "                    predictions.append('spam')\n",
    "                else:\n",
    "                    predictions.append('ham')\n",
    "                \n",
    "                clear_output()\n",
    "                s += 1\n",
    "                print(str(s)+\" out of \"+str(total_size)+\"(\"+str(100*s/total_size)+\"%)\")\n",
    "                \n",
    "        else:\n",
    "            print(\"Model must be trained first.\")\n",
    "        \n",
    "        print(\"Prediction Complete.\")\n",
    "        \n",
    "        return predictions        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = EmailClassifier(frequent_word_percentage = 2)\n",
    "classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16582 out of 16582(100.0%)\n",
      "Prediction Complete.\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8285490290676637\n",
      "Precision (Macro | Micro): 0.8417988488213207  |  0.8285490290676637\n",
      "False Positive Rate (FPR): 0.26452358441012713  |  0.04601444145547218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6738,  325],\n",
       "       [2518, 7001]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_validation, predictions)\n",
    "\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_validation, predictions))\n",
    "print(\"Precision (Macro | Micro):\", precision_score(y_validation, predictions, average='macro'), \" | \", precision_score(y_validation, predictions, average='micro'))\n",
    "print(\"False Positive Rate (FPR):\", FPR[0], \" | \", FPR[1])\n",
    "cnf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test datapaths\n",
    "path = main_file_path + 'test'\n",
    "file_paths = pd.Series(['test/' + filename + '/' + fname for filename in os.listdir(path) for fname in os.listdir(main_file_path + 'test/' + filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plan hi tonight rolling new report currently a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advertising working east power desk purchase s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil ready bill us oil couple want know send in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>per eric moon attached find slide prepay north</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly return path full name message id    date...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email\n",
       "0  plan hi tonight rolling new report currently a...\n",
       "1  advertising working east power desk purchase s...\n",
       "2  oil ready bill us oil couple want know send in...\n",
       "3   per eric moon attached find slide prepay north  \n",
       "4  truly return path full name message id    date..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test emails using the filepaths\n",
    "test_data = file_paths.apply(lambda row: process_email_data(main_file_path + row)).apply(pd.Series)\n",
    "test_data.columns = ['email']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with all training data\n",
    "classifier.train(data[['email']], data[['Label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9283 out of 9283(100.0%)\n",
      "Prediction Complete.\n"
     ]
    }
   ],
   "source": [
    "# Predictions for Test Data\n",
    "predictions = classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the submission file for Kaggle\n",
    "submission = pd.DataFrame({\n",
    "    'Id': file_paths,\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives 0.82958 score on Kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
