{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAT640 - Assignment 1b\n",
    "# Name:    Rabbir Bin Rabbani\n",
    "# ID:      247988\n",
    "# Team:    004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from IPython.display import clear_output # Using IPython.display.clear_output to clear the output of a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please run the preprocessor notebook file to get the preprocessed datasets.\n",
    "I have separated the files for simplicity, convinience and saving time. The datasets can also be downloaded from [this dropbox link](https://www.dropbox.com/sh/htywy8h8rtbm3u7/AAD_zpLznXeBnMMQIzPJa8lda?dl=0).\n",
    "\n",
    "* https://www.dropbox.com/sh/htywy8h8rtbm3u7/AAD_zpLznXeBnMMQIzPJa8lda?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>email</th>\n",
       "      <th>subject_length</th>\n",
       "      <th>body_length</th>\n",
       "      <th>hasReturnPath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/000/000</td>\n",
       "      <td>fw  june       bna  inc  daily labor reportuse...</td>\n",
       "      <td>9</td>\n",
       "      <td>2219</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/000/002</td>\n",
       "      <td>re  intranet siterika   these new         orig...</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/000/003</td>\n",
       "      <td>fw  ena upstream company informationjohn geral...</td>\n",
       "      <td>5</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/000/004</td>\n",
       "      <td>new master physicalgerald and stacy    attache...</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/000/005</td>\n",
       "      <td>fw  ena upstream company mirant gisbfyi  below...</td>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                              email  \\\n",
       "0  train/000/000  fw  june       bna  inc  daily labor reportuse...   \n",
       "1  train/000/002  re  intranet siterika   these new         orig...   \n",
       "2  train/000/003  fw  ena upstream company informationjohn geral...   \n",
       "3  train/000/004  new master physicalgerald and stacy    attache...   \n",
       "4  train/000/005  fw  ena upstream company mirant gisbfyi  below...   \n",
       "\n",
       "   subject_length  body_length  hasReturnPath Label  \n",
       "0               9         2219              1   ham  \n",
       "1               3           71              1   ham  \n",
       "2               5          228              1   ham  \n",
       "3               3           49              1   ham  \n",
       "4               5          196              1   ham  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from drive\n",
    "data = pd.read_csv(\"processed_train_dataset.csv\")\n",
    "data['email'] = data['email'].replace(np.nan, '', regex=True) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, data['Label'], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9572788"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Vectorizer vocabulary\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data['email'])\n",
    "\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66324, 9572788) (16582, 9572788)\n"
     ]
    }
   ],
   "source": [
    "# Count Vectors\n",
    "X_train_vec = vectorizer.transform(X_train['email'])\n",
    "X_val_vec = vectorizer.transform(X_val['email'])\n",
    "\n",
    "print(X_train_vec.shape, X_val_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66324x9572788 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20042132 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66324, 9572788) (16582, 9572788)\n"
     ]
    }
   ],
   "source": [
    "# TF Vectors\n",
    "tf_transformer = TfidfTransformer(norm='l1', use_idf=False)\n",
    "\n",
    "X_train_vec_tf = tf_transformer.fit_transform(X_train_vec)\n",
    "X_val_vec_tf = tf_transformer.fit_transform(X_val_vec)\n",
    "\n",
    "print(X_train_vec_tf.shape, X_val_vec_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66324, 9572788) (16582, 9572788)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectors\n",
    "tfidf_transformer = TfidfTransformer(norm='l1', use_idf=True)\n",
    "\n",
    "X_train_vec_tfidf = tfidf_transformer.fit_transform(X_train_vec)\n",
    "X_val_vec_tfidf = tfidf_transformer.fit_transform(X_val_vec)\n",
    "\n",
    "print(X_train_vec_tfidf.shape, X_val_vec_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    'Algorithm': [],\n",
    "    'Term Weighting': [],\n",
    "    'Acc': [],\n",
    "    'Prec': [],\n",
    "    'FPR': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive-Bayes Classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Naive-Bayes with Count\n",
    "classifier.fit(X_train_vec, y_train)\n",
    "predictions = classifier.predict(X_val_vec)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('Naive Bayes')\n",
    "scores['Term Weighting'].append('Count')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))\n",
    "\n",
    "# Naive-Bayes with Term Frequency\n",
    "classifier.fit(X_train_vec_tf, y_train)\n",
    "predictions = classifier.predict(X_val_vec_tf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('Naive Bayes')\n",
    "scores['Term Weighting'].append('TF')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))\n",
    "\n",
    "# Naive-Bayes with Term Frequency-Inverse Document Frequency\n",
    "classifier.fit(X_train_vec_tfidf, y_train)\n",
    "predictions = classifier.predict(X_val_vec_tfidf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('Naive Bayes')\n",
    "scores['Term Weighting'].append('TF-IDF')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rabbi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Classifier\n",
    "classifier = LinearSVC(random_state = 0)\n",
    "\n",
    "# SVM with Count\n",
    "classifier.fit(X_train_vec, y_train)\n",
    "predictions = classifier.predict(X_val_vec)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('SVM')\n",
    "scores['Term Weighting'].append('Count')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))\n",
    "\n",
    "# SVM with Term Frequency\n",
    "classifier.fit(X_train_vec_tf, y_train)\n",
    "predictions = classifier.predict(X_val_vec_tf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('SVM')\n",
    "scores['Term Weighting'].append('TF')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))\n",
    "\n",
    "# SVM with Term Frequency-Inverse Document Frequency\n",
    "classifier.fit(X_train_vec_tfidf, y_train)\n",
    "predictions = classifier.predict(X_val_vec_tfidf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('SVM')\n",
    "scores['Term Weighting'].append('TF-IDF')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Term Weighting</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Prec</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.924979</td>\n",
       "      <td>0.895366</td>\n",
       "      <td>0.155033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF</td>\n",
       "      <td>0.895489</td>\n",
       "      <td>0.847713</td>\n",
       "      <td>0.241399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.910264</td>\n",
       "      <td>0.866947</td>\n",
       "      <td>0.206145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.982270</td>\n",
       "      <td>0.980920</td>\n",
       "      <td>0.025910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF</td>\n",
       "      <td>0.961163</td>\n",
       "      <td>0.951562</td>\n",
       "      <td>0.067393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.967314</td>\n",
       "      <td>0.956102</td>\n",
       "      <td>0.061164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Algorithm Term Weighting       Acc      Prec       FPR\n",
       "0  Naive Bayes          Count  0.924979  0.895366  0.155033\n",
       "1  Naive Bayes             TF  0.895489  0.847713  0.241399\n",
       "2  Naive Bayes         TF-IDF  0.910264  0.866947  0.206145\n",
       "3          SVM          Count  0.982270  0.980920  0.025910\n",
       "4          SVM             TF  0.961163  0.951562  0.067393\n",
       "5          SVM         TF-IDF  0.967314  0.956102  0.061164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the new Features to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9572788"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data['email'])\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82906, 9572788)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec = vectorizer.transform(data['email'])\n",
    "data_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the additional features to the sparse matrix to get the count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data sparse matrix with the additional featurer\n",
    "data_vec = sparse.hstack((data_vec, data[['subject_length', 'body_length', 'hasReturnPath']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_vec, data['Label'], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    'Algorithm': [],\n",
    "    'Term Weighting': [],\n",
    "    'Acc': [],\n",
    "    'Prec': [],\n",
    "    'FPR': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rabbi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Rabbi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "classifier = MultinomialNB().fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('Naive Bayes')\n",
    "scores['Term Weighting'].append('Count')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))\n",
    "\n",
    "# Linear SVM\n",
    "classifier = LinearSVC(random_state = 0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('SVM')\n",
    "scores['Term Weighting'].append('Count')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))\n",
    "\n",
    "# Logistic Regression\n",
    "classifier = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('Logistic Regression')\n",
    "scores['Term Weighting'].append('Count')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "scores['Algorithm'].append('Decision Tree')\n",
    "scores['Term Weighting'].append('Count')\n",
    "scores['Acc'].append((tp + tn) / (tp + tn + fp + fn))\n",
    "scores['Prec'].append((tp / (tp + fp)))\n",
    "scores['FPR'].append((fp / (fp + tn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Term Weighting</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Prec</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.878241</td>\n",
       "      <td>0.831272</td>\n",
       "      <td>0.270423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.990894</td>\n",
       "      <td>0.991501</td>\n",
       "      <td>0.011468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.975697</td>\n",
       "      <td>0.987070</td>\n",
       "      <td>0.017132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.989446</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>0.012318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm Term Weighting       Acc      Prec       FPR\n",
       "0          Naive Bayes          Count  0.878241  0.831272  0.270423\n",
       "1                  SVM          Count  0.990894  0.991501  0.011468\n",
       "2  Logistic Regression          Count  0.975697  0.987070  0.017132\n",
       "3        Decision Tree          Count  0.989446  0.990859  0.012318"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train SVM with entire train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rabbi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "classifier = LinearSVC(random_state = 0).fit(data_vec, data['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and transform the test dataset.\n",
    "test_data = pd.read_csv(\"processed_test_dataset.csv\")\n",
    "test_data['email'] = test_data['email'].replace(np.nan, '', regex=True) \n",
    "\n",
    "test_data_vec = vectorizer.transform(test_data['email'])\n",
    "test_data_vec = sparse.hstack((test_data_vec, test_data[['subject_length', 'body_length', 'hasReturnPath']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the predictions to csv for submitting to Kaggle.\n",
    "test_data['Label'] = classifier.predict(test_data_vec)\n",
    "test_data[['Id','Label']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
