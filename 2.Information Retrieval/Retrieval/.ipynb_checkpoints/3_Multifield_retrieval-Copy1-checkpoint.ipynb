{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2A, Part 3: Multifield retrieval\n",
    "\n",
    "Implement BM25F and the Mixture of Language Models (MLM). Use two fields: title and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FILE = \"data/queries.txt\"  # make sure the query file exists on this location\n",
    "OUTPUT_FILE = \"data/output.txt\"  # output the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: place the indexing related code here. This may be copy-pasted from Part 1.\n",
    "indx, d_len, PtC, avg_len = [], [], [], [0, 0] # one index for each parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx.append(pickle.load(open(\"data/title_indx.p\", \"rb\")))\n",
    "d_len.append(pickle.load(open(\"data/title_d_len.p\", \"rb\")))\n",
    "PtC.append(pickle.load(open(\"data/title_PtC.p\", \"rb\")))\n",
    "NUM_DOCS = len(d_len[0])\n",
    "avg_len[0] = sum(list(d_len[0].values()))/NUM_DOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx.append(pickle.load(open(\"data/content_indx.p\", \"rb\")))\n",
    "d_len.append(pickle.load(open(\"data/content_d_len.p\", \"rb\")))\n",
    "PtC.append(pickle.load(open(\"data/content_PtC.p\", \"rb\")))\n",
    "avg_len[1] = sum(list(d_len[1].values()))/NUM_DOCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the queries from the file\n",
    "\n",
    "See the assignment description for the format of the query file [here](https://github.com/kbalog/uis-dat640-fall2019/tree/master/assignments/assignment-2a#queries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(query_file):\n",
    "    queries = {}\n",
    "    with open(query_file, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            qid, query = line.strip().split(\" \", 1)\n",
    "            queries[qid] = query\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "queries = load_queries(QUERY_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_idf(word, n):\n",
    "    return math.log(NUM_DOCS / n)\n",
    "\n",
    "# TODO write your scoring code here\n",
    "def BM25f(q_id, query, k1, b, weights):\n",
    "    scores = {}\n",
    "    \n",
    "    words = nltk.word_tokenize(query.lower())\n",
    "    \n",
    "    for word in list(set(words)):\n",
    "        for i, w_i in enumerate(weights):\n",
    "            if word in list(indx[i].keys()):\n",
    "                f_td = {}\n",
    "                \n",
    "                idf = calc_idf(word, len(indx[i][word]))\n",
    "                \n",
    "                for (doc_id, freq) in indx[i][word].items():                    \n",
    "                    B_i = 1 - b[i] + b[i]*(d_len[i][doc_id]/avg_len[i])\n",
    "                    \n",
    "                    f_td[doc_id] = f_td.get(doc_id, 0) + (w_i*(freq/B_i))\n",
    "                    \n",
    "                    score = round(idf*(f_td[doc_id]/(k1 + f_td[doc_id])), 3)\n",
    "                    scores[doc_id] = scores.get(doc_id, 0) + score\n",
    "\n",
    "    \n",
    "    \n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse = True)\n",
    "    scores = scores[:100]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def MLM(q_id, query, l, weights):    \n",
    "    scores = {}\n",
    "    words = nltk.word_tokenize(query.lower())\n",
    "    \n",
    "    for word in list(set(words)):\n",
    "        for i, w_i in enumerate(weights):\n",
    "            if (word in list(indx[i].keys())):\n",
    "                for (doc_id, freq) in indx[i][word].items():\n",
    "                    score = w_i*((1-l[i])*(freq / d_len[i][doc_id]) + (l[i]*PtC[i][word]))\n",
    "                    scores[doc_id] = scores.get(doc_id, 0) + score\n",
    "\n",
    "    for doc_id, score in scores.items():\n",
    "        scores[doc_id] = math.log(scores[doc_id])\n",
    "    \n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse = True)\n",
    "    scores = scores[:100]\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Generate a ranking for each query and output the results to `OUTPUT_FILE`\n",
    "\n",
    "See the assignment description for the format of the output file [here](https://github.com/kbalog/uis-dat640-fall2019/tree/master/assignments/assignment-2a#output-file-format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "BM25f_QueryId = []\n",
    "BM25f_DocumentId = []\n",
    "MLM_QueryId = []\n",
    "MLM_DocumentId = []\n",
    "\n",
    "for q_id, query in queries.items():\n",
    "    # TODO generate ranking\n",
    "    \n",
    "    BM25f_res = BM25f(q_id,query,k1=1.2,b=[0.3, 0.2],weights=[0.1, 0.9])\n",
    "    for score in BM25f_res:\n",
    "        BM25f_QueryId.append(q_id)\n",
    "        BM25f_DocumentId.append(score[0])\n",
    "    \n",
    "    MLM_res = MLM(q_id, query,l=[0.8,0.8],weights=[0.1, 0.9])\n",
    "    for score in MLM_res:\n",
    "        MLM_QueryId.append(q_id)\n",
    "        MLM_DocumentId.append(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scores to files\n",
    "data = pd.DataFrame()\n",
    "data['QueryId'] = BM25f_QueryId\n",
    "data['DocumentId'] = BM25f_DocumentId\n",
    "data.to_csv(\"bm25f_multifield.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['QueryId'] = MLM_QueryId\n",
    "data['DocumentId'] = MLM_DocumentId\n",
    "data.to_csv(\"mlm_multifield.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Report on the evaluation results (using the [Evaluation notebook](1_Evaluation.ipynb)) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found my parameters by trying different values.\n",
    "\n",
    "\n",
    "| **Method** | **Parameter settings** | **Output file** | **P@10** | **MAP** | **MRR** |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "| BM25F | k1: 1.2, b: [0.3, 0.2], $w_{title}$: 0.1, $w_{content}$: 0.9 | `data/bm25f_multifield.csv` | 0.193 | 0.073 | 0.313 |\n",
    "| MLM | Smoothing method: Jelinek-Mercer, smoothing param: lambda = [0.8,0.8], $w_{title}$: 0.9, $w_{content}$: 0.1 | `data/mlm_multifield.csv` | 0.144 | 0.051 | 0.245 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
