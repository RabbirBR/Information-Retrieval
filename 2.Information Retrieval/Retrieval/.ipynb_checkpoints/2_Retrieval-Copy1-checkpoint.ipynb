{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2A, Part 2: Retrieval\n",
    "\n",
    "Implement BM25 and LM retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FILE = \"data/queries.txt\"  # make sure the query file exists on this location\n",
    "OUTPUT_FILE = \"data/output.txt\"  # output the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_indx = pickle.load(open(\"data/content_indx.p\", \"rb\" ))\n",
    "content_d_len = pickle.load(open(\"data/content_d_len.p\", \"rb\" ))\n",
    "content_PtC = pickle.load(open(\"data/content_PtC.p\", \"rb\" ))\n",
    "NUM_DOCS = len(content_d_len)\n",
    "avg_len = sum(list(content_d_len.values()))/NUM_DOCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the queries from the file\n",
    "\n",
    "See the assignment description for the format of the query file [here](https://github.com/kbalog/uis-dat640-fall2019/tree/master/assignments/assignment-2a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(query_file):\n",
    "    queries = {}\n",
    "    with open(query_file, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            qid, query = line.strip().split(\" \", 1)\n",
    "            queries[qid] = query\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "queries = load_queries(QUERY_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_idf(word):\n",
    "    n = len(content_indx[word])\n",
    "    return math.log((NUM_DOCS - n + 0.5) / (n + 0.5))\n",
    "\n",
    "\n",
    "# TODO write your scoring code here\n",
    "def BM25(q_id, query, k1, b):\n",
    "    scores = {}\n",
    "    words = nltk.word_tokenize(query.lower())\n",
    "    \n",
    "    for word in set(words):\n",
    "        if word in list(content_indx.keys()):\n",
    "            for (doc_id, freq) in content_indx[word].items():\n",
    "                idf = calc_idf(word)\n",
    "                \n",
    "                score =  idf*(freq * (k1 + 1)) / (freq + k1*(1 - b + b*(content_d_len[doc_id]/avg_len)))\n",
    "                score = round(score, 3)\n",
    "                \n",
    "                scores[doc_id] = scores.get(doc_id, 0) + score\n",
    "                \n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse = True)\n",
    "    scores = scores[:100]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def LM(q_id, query, l):    \n",
    "    scores = {}\n",
    "    words = nltk.word_tokenize(query.lower())\n",
    "    \n",
    "    for word in set(words):\n",
    "        ftq = words.count(word)\n",
    "        \n",
    "        if word in list(content_indx.keys()):\n",
    "            for (doc_id, freq) in content_indx[word].items():\n",
    "                score =  round(math.log((1-l)*(freq / content_d_len[doc_id]) + (l*content_PtC[word])), 3)\n",
    "    \n",
    "                scores[doc_id] = scores.get(doc_id, 0) + score\n",
    "            scores[doc_id] = ftq * scores[doc_id]\n",
    "    \n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse = True)\n",
    "    scores = scores[:100]\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Generate a ranking for each query and output the results to `OUTPUT_FILE`\n",
    "\n",
    "See the assignment description for the format of the output file [here](https://github.com/kbalog/uis-dat640-fall2019/tree/master/assignments/assignment-2a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25_QueryId = []\n",
    "BM25_DocumentId = []\n",
    "LM_QueryId = []\n",
    "LM_DocumentId = []\n",
    "\n",
    "for q_id, query in queries.items():\n",
    "    # TODO generate ranking\n",
    "    \n",
    "    BM_25_res = BM25(q_id,query,k1=1.2,b=0.7)\n",
    "    for score in BM_25_res:\n",
    "        BM25_QueryId.append(q_id)\n",
    "        BM25_DocumentId.append(score[0])\n",
    "    \n",
    "    LM_res = LM(q_id, query, l=0.8)\n",
    "    for score in LM_res:\n",
    "        LM_QueryId.append(q_id)\n",
    "        LM_DocumentId.append(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scores to files\n",
    "data = pd.DataFrame()\n",
    "data['QueryId'] = BM25_QueryId\n",
    "data['DocumentId'] = BM25_DocumentId\n",
    "data.to_csv(\"bm25_singlefield.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['QueryId'] = LM_QueryId\n",
    "data['DocumentId'] = LM_DocumentId\n",
    "data.to_csv(\"lm_singlefield.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Report on the evaluation results (using the [Evaluation notebook](1_Evaluation.ipynb)) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the parameter settings used for the two methods: \n",
    "\n",
    "Parameters for BM25: k1 = 1.2, b = 0.7\n",
    "\n",
    "Parameters for LM: lambda = 0.8\n",
    "\n",
    "Write the name of the corresponding output file in the table. These files should be pushed to your repository.\n",
    "\n",
    "| **Method** | **Output file** | **P@10** | **MAP** | **MRR** |\n",
    "| -- | -- | -- | -- | -- |\n",
    "| BM25 | `bm25_singlefield.csv` | 0.184 | 0.067 | 0.319 |\n",
    "| LM | `lm_singlefield.csv` | 0.036 | 0.012 | 0.084 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
